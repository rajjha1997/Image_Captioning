{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 882/414113 [00:00<01:36, 4300.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:29<00:00, 4607.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from data_loader import get_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Preprocessing of training images\n",
    "tt = transforms.Compose([ \n",
    "    transforms.Resize(256),                          \n",
    "    transforms.RandomCrop(224),                      \n",
    "    transforms.RandomHorizontalFlip(),               \n",
    "    transforms.ToTensor(),                           \n",
    "    transforms.Normalize((0.485, 0.456, 0.406),     \n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Set the minimum word count threshold.\n",
    "min_word_threshold = 4\n",
    "\n",
    "# Specify the batch size.\n",
    "batch_size = 10\n",
    "\n",
    "# Obtain the data loader.\n",
    "data_loader = get_loader(transform=tt,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=min_word_threshold,\n",
    "                         vocab_from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_smpl = 'A person doing a trick on a rail while riding a skateboard.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'person', 'doing', 'a', 'trick', 'on', 'a', 'rail', 'while', 'riding', 'a', 'skateboard', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokens_smpl = nltk.tokenize.word_tokenize(str(caption_smpl).lower())\n",
    "print(tokens_smpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the start word of the caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special start word: <start>\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "image_caption = []\n",
    "\n",
    "start_word = data_loader.dataset.vocab.start_word\n",
    "print('Special start word:', start_word)\n",
    "\n",
    "image_caption.append(data_loader.dataset.vocab(start_word))\n",
    "print(image_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the start symbol to all caption of the data loader dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[0, 3, 98, 756, 3, 396, 39, 3, 1014, 207, 139, 3, 755, 18]\n"
     ]
    }
   ],
   "source": [
    "image_caption.extend([data_loader.dataset.vocab(token) for token in tokens_smpl])\n",
    "print(len(image_caption))\n",
    "print(image_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the end symbol of the caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special end word: <end>\n",
      "[0, 3, 98, 756, 3, 396, 39, 3, 1014, 207, 139, 3, 755, 18, 1]\n"
     ]
    }
   ],
   "source": [
    "end_symbol = data_loader.dataset.vocab.end_word\n",
    "print('Special end word:', end_symbol)\n",
    "\n",
    "image_caption.append(data_loader.dataset.vocab(end_symbol))\n",
    "print(image_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of list of tensors to long type int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     3,    98,   756,     3,   396,    39,     3,  1014,\n",
      "          207,   139,     3,   755,    18,     1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "image_caption = torch.Tensor(image_caption).long()\n",
    "print(image_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 0,\n",
       " '<end>': 1,\n",
       " '<unk>': 2,\n",
       " 'a': 3,\n",
       " 'very': 4,\n",
       " 'clean': 5,\n",
       " 'and': 6,\n",
       " 'well': 7,\n",
       " 'decorated': 8,\n",
       " 'empty': 9}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the word2idx dictionary.\n",
    "dict(list(data_loader.dataset.vocab.word2idx.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in vocabulary: 9955\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of keys in the word2idx dictionary.\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this for yourself below, by pre-processing the provided nonsense words that never appear in the training captions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:29<00:00, 4605.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "# Obtain the data loader (from file). Note that it runs much faster than before!\n",
    "data_loader = get_loader(transform=tt,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_from_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Batches of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 10 --- count: 86334\n",
      "value: 11 --- count: 79948\n",
      "value:  9 --- count: 71934\n",
      "value: 12 --- count: 57637\n",
      "value: 13 --- count: 37645\n",
      "value: 14 --- count: 22335\n",
      "value:  8 --- count: 20771\n",
      "value: 15 --- count: 12841\n",
      "value: 16 --- count:  7729\n",
      "value: 17 --- count:  4842\n",
      "value: 18 --- count:  3104\n",
      "value: 19 --- count:  2014\n",
      "value:  7 --- count:  1597\n",
      "value: 20 --- count:  1451\n",
      "value: 21 --- count:   999\n",
      "value: 22 --- count:   683\n",
      "value: 23 --- count:   534\n",
      "value: 24 --- count:   383\n",
      "value: 25 --- count:   277\n",
      "value: 26 --- count:   215\n",
      "value: 27 --- count:   159\n",
      "value: 28 --- count:   115\n",
      "value: 29 --- count:    86\n",
      "value: 30 --- count:    58\n",
      "value: 31 --- count:    49\n",
      "value: 32 --- count:    44\n",
      "value: 34 --- count:    39\n",
      "value: 37 --- count:    32\n",
      "value: 33 --- count:    31\n",
      "value: 35 --- count:    31\n",
      "value: 36 --- count:    26\n",
      "value: 38 --- count:    18\n",
      "value: 39 --- count:    18\n",
      "value: 43 --- count:    16\n",
      "value: 44 --- count:    16\n",
      "value: 48 --- count:    12\n",
      "value: 45 --- count:    11\n",
      "value: 42 --- count:    10\n",
      "value: 40 --- count:     9\n",
      "value: 49 --- count:     9\n",
      "value: 46 --- count:     9\n",
      "value: 47 --- count:     7\n",
      "value: 50 --- count:     6\n",
      "value: 51 --- count:     6\n",
      "value: 41 --- count:     6\n",
      "value: 52 --- count:     5\n",
      "value: 54 --- count:     3\n",
      "value: 56 --- count:     2\n",
      "value:  6 --- count:     2\n",
      "value: 53 --- count:     2\n",
      "value: 55 --- count:     2\n",
      "value: 57 --- count:     1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "total_training_captions = Counter(data_loader.dataset.caption_lengths)\n",
    "each_caption_length = sorted(total_training_captions.items(), key=lambda pair: pair[1], reverse=True)\n",
    "for value, count in each_caption_length:\n",
    "    print('value: %2d --- count: %5d' % (value, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled indices: [255961, 384592, 240469, 196185, 292053, 169926, 392656, 404516, 354966, 353065]\n",
      "images.shape: torch.Size([10, 3, 224, 224])\n",
      "captions.shape: torch.Size([10, 16])\n",
      "images: tensor([[[[ 0.8104,  0.8276,  0.7933,  ...,  1.2385,  1.2557,  1.2385],\n",
      "          [ 0.8104,  0.8447,  0.7933,  ...,  1.2043,  1.2043,  1.2043],\n",
      "          [ 0.7591,  0.8104,  0.7933,  ...,  1.1872,  1.1872,  1.1700],\n",
      "          ...,\n",
      "          [-0.6794, -0.7479, -0.9363,  ..., -0.6452, -0.6623, -0.7479],\n",
      "          [-0.7308, -0.7650, -1.0904,  ..., -0.8335, -0.6965, -0.8164],\n",
      "          [-0.6965, -0.9877, -1.4329,  ..., -1.2959, -1.2617, -1.3815]],\n",
      "\n",
      "         [[ 1.2031,  1.2381,  1.1856,  ...,  1.5707,  1.5707,  1.5882],\n",
      "          [ 1.2031,  1.2381,  1.2031,  ...,  1.5532,  1.5532,  1.5707],\n",
      "          [ 1.1681,  1.1856,  1.1856,  ...,  1.5707,  1.5707,  1.5532],\n",
      "          ...,\n",
      "          [-0.7402, -0.7752, -0.8978,  ..., -0.3550, -0.4076, -0.4601],\n",
      "          [-0.7577, -0.7402, -0.9678,  ..., -0.6877, -0.5826, -0.6352],\n",
      "          [-0.7227, -0.9153, -1.2829,  ..., -1.1954, -1.1604, -1.2829]],\n",
      "\n",
      "         [[ 1.9254,  1.9254,  1.9254,  ...,  2.1346,  2.1171,  2.0997],\n",
      "          [ 1.9080,  1.9428,  1.9428,  ...,  2.0997,  2.0997,  2.0823],\n",
      "          [ 1.9080,  1.9080,  1.9080,  ...,  2.0997,  2.0823,  2.0474],\n",
      "          ...,\n",
      "          [-0.9853, -0.9504, -1.0898,  ..., -1.2467, -1.3687, -1.3861],\n",
      "          [-1.0376, -1.0550, -1.1944,  ..., -1.2990, -1.2641, -1.4210],\n",
      "          [-0.9678, -1.1596, -1.3687,  ..., -1.3339, -1.4384, -1.5430]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8037,  1.8037,  1.8208,  ..., -0.0972, -0.1657, -0.1143],\n",
      "          [ 1.8722,  1.8893,  1.8893,  ...,  0.1254,  0.1939,  0.1597],\n",
      "          [ 0.9817,  1.0673,  1.1700,  ...,  0.2282,  0.3481,  0.4508],\n",
      "          ...,\n",
      "          [ 0.0569,  0.1768,  0.2624,  ...,  1.2557,  1.1529,  1.1358],\n",
      "          [-0.0116,  0.0569,  0.0056,  ...,  1.1872,  1.1872,  1.1700],\n",
      "          [ 0.1254,  0.1426,  0.0056,  ...,  1.0844,  1.1358,  1.2043]],\n",
      "\n",
      "         [[ 2.2360,  2.2185,  2.2535,  ...,  0.0476, -0.0224,  0.0301],\n",
      "          [ 2.2710,  2.2535,  2.2710,  ...,  0.2927,  0.3452,  0.3277],\n",
      "          [ 1.7458,  1.8158,  1.9209,  ...,  0.4153,  0.5028,  0.6429],\n",
      "          ...,\n",
      "          [ 0.5728,  0.6604,  0.8004,  ...,  0.6254,  0.5378,  0.3452],\n",
      "          [ 0.5203,  0.6604,  0.5728,  ...,  0.4328,  0.4503,  0.4503],\n",
      "          [ 0.7479,  0.7129,  0.5728,  ...,  0.3627,  0.5028,  0.4678]],\n",
      "\n",
      "         [[ 2.6051,  2.5877,  2.5703,  ...,  0.0953,  0.0953,  0.1825],\n",
      "          [ 2.5529,  2.5354,  2.5877,  ...,  0.3045,  0.5136,  0.4962],\n",
      "          [ 2.3263,  2.3263,  2.3437,  ...,  0.4788,  0.7054,  0.7925],\n",
      "          ...,\n",
      "          [-0.3404, -0.1312,  0.0431,  ...,  0.4439,  0.3045,  0.0779],\n",
      "          [-0.4450, -0.2881, -0.2881,  ...,  0.2348,  0.2871,  0.2348],\n",
      "          [-0.3404, -0.4275, -0.4275,  ...,  0.0431,  0.1302,  0.1476]]],\n",
      "\n",
      "\n",
      "        [[[-1.9809, -1.9638, -1.8953,  ..., -1.0390, -1.0219, -0.9705],\n",
      "          [-2.0152, -1.9980, -1.9638,  ..., -0.9705, -0.9705, -0.9020],\n",
      "          [-2.0152, -2.0152, -1.9980,  ..., -0.9363, -0.9705, -0.8678],\n",
      "          ...,\n",
      "          [-0.0458,  0.0912,  0.2282,  ..., -0.1828, -0.1999, -0.2513],\n",
      "          [ 0.3652,  0.2282, -0.2684,  ..., -0.1828, -0.1657, -0.1999],\n",
      "          [ 0.1768, -0.2171,  0.1083,  ..., -0.2513, -0.2342, -0.2684]],\n",
      "\n",
      "         [[-1.8606, -1.8431, -1.7206,  ..., -0.7052, -0.6877, -0.6877],\n",
      "          [-1.9132, -1.8957, -1.8431,  ..., -0.7052, -0.6527, -0.7052],\n",
      "          [-1.9132, -1.9307, -1.8957,  ..., -0.7402, -0.6702, -0.7052],\n",
      "          ...,\n",
      "          [-0.0399,  0.0826,  0.2227,  ..., -0.7402, -0.6527, -0.7052],\n",
      "          [ 0.2927,  0.1352, -0.1625,  ..., -0.7227, -0.6702, -0.7052],\n",
      "          [ 0.0651, -0.1625, -0.0224,  ..., -0.7052, -0.6877, -0.7577]],\n",
      "\n",
      "         [[-1.6650, -1.6127, -1.4559,  ..., -0.8633, -0.9156, -0.8633],\n",
      "          [-1.6999, -1.6650, -1.5953,  ..., -0.8284, -0.8633, -0.8458],\n",
      "          [-1.6999, -1.6999, -1.6650,  ..., -0.8633, -0.8633, -0.8458],\n",
      "          ...,\n",
      "          [ 0.0953,  0.1651,  0.1999,  ..., -0.8633, -0.9504, -0.9156],\n",
      "          [ 0.3916,  0.1999, -0.1835,  ..., -0.7936, -0.8807, -0.8284],\n",
      "          [ 0.1302, -0.0790,  0.0953,  ..., -0.7413, -0.8110, -0.8110]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3883, -0.5938, -0.6965,  ...,  0.0741, -0.0629,  0.3823],\n",
      "          [-0.2856, -0.7137, -0.6965,  ...,  0.0912, -0.0458,  0.7762],\n",
      "          [-0.4568, -0.9020, -0.9363,  ...,  0.0569, -0.0629,  0.4851],\n",
      "          ...,\n",
      "          [-0.3541, -0.3712, -0.2684,  ...,  0.0398, -0.0458, -0.0801],\n",
      "          [-0.2171, -0.1828, -0.2342,  ...,  0.0056, -0.0287, -0.0458],\n",
      "          [-0.1657, -0.1314, -0.1486,  ...,  0.0227, -0.0287, -0.0458]],\n",
      "\n",
      "         [[-0.1625, -0.3200, -0.4776,  ...,  0.1877,  0.0301,  0.4853],\n",
      "          [-0.2675, -0.5126, -0.3725,  ...,  0.2227,  0.0476,  0.8880],\n",
      "          [-0.3200, -0.7227, -0.7052,  ...,  0.2402,  0.0476,  0.5728],\n",
      "          ...,\n",
      "          [ 0.2752,  0.2402,  0.3452,  ...,  0.5728,  0.4153,  0.4328],\n",
      "          [ 0.3452,  0.3978,  0.3803,  ...,  0.5728,  0.4853,  0.4853],\n",
      "          [ 0.4678,  0.4853,  0.4678,  ...,  0.5903,  0.6078,  0.5553]],\n",
      "\n",
      "         [[-0.4973, -0.5670, -0.6541,  ..., -0.0441,  0.0256,  0.4439],\n",
      "          [-0.3578, -0.7413, -0.7064,  ..., -0.0092, -0.0267,  0.9842],\n",
      "          [-0.4275, -0.7761, -0.7761,  ..., -0.2707, -0.1487,  0.6705],\n",
      "          ...,\n",
      "          [-0.4798, -0.4101, -0.3404,  ..., -0.1138, -0.2184, -0.1835],\n",
      "          [-0.3578, -0.2532, -0.2184,  ..., -0.0790, -0.1835, -0.1835],\n",
      "          [-0.4101, -0.2881, -0.2184,  ..., -0.1312, -0.1661, -0.2881]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8618,  0.8104,  0.7248,  ...,  1.1529,  0.7933,  0.4508],\n",
      "          [ 0.6906,  0.8789,  0.7762,  ...,  1.1529,  0.7933,  0.2967],\n",
      "          [ 0.7933,  0.7762,  0.8276,  ...,  1.1358,  0.8104,  0.4508],\n",
      "          ...,\n",
      "          [ 0.5878,  0.5707,  0.6392,  ...,  0.5536,  0.2967,  0.2624],\n",
      "          [ 0.6049,  0.5536,  0.6221,  ...,  0.3994,  0.3481,  0.3309],\n",
      "          [ 0.6049,  0.5364,  0.4679,  ...,  0.4679,  0.3823,  0.2967]],\n",
      "\n",
      "         [[ 0.4678,  0.5378,  0.6429,  ...,  0.8354,  0.5203,  0.1176],\n",
      "          [ 0.5553,  0.5553,  0.5553,  ...,  0.7479,  0.4153,  0.1877],\n",
      "          [ 0.5028,  0.6604,  0.5903,  ...,  0.7304,  0.3627,  0.1702],\n",
      "          ...,\n",
      "          [ 0.1527,  0.1527,  0.1702,  ...,  0.0476, -0.0049, -0.2150],\n",
      "          [ 0.2402,  0.1702,  0.1001,  ..., -0.0224, -0.1099, -0.2850],\n",
      "          [ 0.0826,  0.1001,  0.1176,  ...,  0.0826, -0.0924, -0.3550]],\n",
      "\n",
      "         [[-0.2707,  0.2348,  0.0082,  ...,  0.1476, -0.2358, -0.0267],\n",
      "          [-0.1312, -0.0615,  0.1825,  ...,  0.2696, -0.0964, -0.1312],\n",
      "          [ 0.0605, -0.3055, -0.3404,  ...,  0.2173, -0.1487, -0.0092],\n",
      "          ...,\n",
      "          [-0.3578, -0.5147, -0.3927,  ..., -0.2184, -0.0615, -0.6541],\n",
      "          [-0.4624, -0.3230, -0.1661,  ..., -0.0790, -0.0441, -0.6018],\n",
      "          [-0.3753, -0.1138, -0.1312,  ..., -0.2184, -0.2707, -0.3927]]],\n",
      "\n",
      "\n",
      "        [[[-1.9638, -1.9809, -1.9980,  ...,  1.8037,  1.8208,  1.7523],\n",
      "          [-1.9467, -1.9467, -1.9124,  ...,  1.5468,  1.5639,  1.4954],\n",
      "          [-0.8164, -0.6965, -0.5767,  ...,  1.4269,  1.4269,  1.4269],\n",
      "          ...,\n",
      "          [-1.6555, -1.6384, -1.6384,  ..., -0.1486, -0.0458, -0.3541],\n",
      "          [-1.6213, -1.3815, -1.1760,  ..., -0.2171, -0.3541, -0.7479],\n",
      "          [-0.9877, -0.3712,  0.3138,  ..., -0.4911, -0.5596, -0.8335]],\n",
      "\n",
      "         [[-1.9307, -1.9132, -1.9307,  ...,  2.0784,  2.0784,  2.0784],\n",
      "          [-1.7556, -1.7381, -1.6856,  ...,  1.8683,  1.8859,  1.9034],\n",
      "          [-0.5476, -0.4426, -0.3025,  ...,  1.8158,  1.8333,  1.8333],\n",
      "          ...,\n",
      "          [-0.0049,  0.0126,  0.0126,  ...,  0.4678,  0.5378,  0.2752],\n",
      "          [-0.0049,  0.1176,  0.1702,  ...,  0.5028,  0.4153,  0.2227],\n",
      "          [ 0.3452,  0.7829,  1.2556,  ...,  0.4153,  0.3452,  0.1176]],\n",
      "\n",
      "         [[-1.6650, -1.6650, -1.6824,  ...,  2.3437,  2.3263,  2.3437],\n",
      "          [-1.6999, -1.6824, -1.6476,  ...,  2.1171,  2.0997,  2.1346],\n",
      "          [-0.5495, -0.4275, -0.3404,  ...,  2.0300,  2.0300,  2.0823],\n",
      "          ...,\n",
      "          [ 0.2522,  0.2871,  0.3568,  ...,  0.6008,  0.6879,  0.4439],\n",
      "          [ 0.2696,  0.3916,  0.5485,  ...,  0.6705,  0.5485,  0.3393],\n",
      "          [ 0.6531,  0.9319,  1.4722,  ...,  0.5659,  0.4962,  0.2871]]]])\n",
      "captions: tensor([[    0,     3,   372,  3574,  1146,    77,    32,   644,    13,\n",
      "             3,  4078,    77,     3,   770,    18,     1],\n",
      "        [    0,     3,   169,  6387,   732,     3,  2359,   147,    86,\n",
      "           108,   161,  1612,    32,   353,    18,     1],\n",
      "        [    0,     3,   169,    21,     3,   371,   130,   108,   161,\n",
      "           354,     3,   858,    21,   456,    18,     1],\n",
      "        [    0,     3,    80,    13,    51,   170,   192,     3,  1523,\n",
      "            61,    21,     3,  3871,  5809,    18,     1],\n",
      "        [    0,     3,  1017,    81,   319,   294,     3,   318,   269,\n",
      "           207,   524,  1017,   716,    39,    18,     1],\n",
      "        [    0,     3,    80,    13,   344,     6,  2307,   272,   364,\n",
      "           161,     3,  2666,    77,    32,   514,     1],\n",
      "        [    0,     3,   169,    21,  2678,    77,   121,    13,   365,\n",
      "            86,   285,   161,   160,  2124,    18,     1],\n",
      "        [    0,    32,    98,    77,     3,    19,  5662,   130,   360,\n",
      "             3,   267,   386,   408,  1676,    18,     1],\n",
      "        [    0,     3,   652,   653,   233,    39,     3,   272,    77,\n",
      "             3,    28,    21,   932,    44,    18,     1],\n",
      "        [    0,     3,   335,    60,     6,    20,   371,   360,     3,\n",
      "           356,    77,    46,   408,  1588,    18,     1]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "idxs = data_loader.dataset.get_train_indices()\n",
    "print('sampled indices:', idxs)\n",
    "\n",
    "\n",
    "sampler_new = data.sampler.SubsetRandomSampler(indices=idxs)\n",
    "data_loader.batch_sampler.sampler = sampler_new\n",
    "    \n",
    "\n",
    "img, image_captions = next(iter(data_loader))\n",
    "    \n",
    "print('images.shape:', img.shape)\n",
    "print('captions.shape:', image_captions.shape)\n",
    "\n",
    "\n",
    "print('images:', img)\n",
    "print('captions:', image_captions)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
